[
    
    
    {
        "url": "/docs/security/data-source/",
        "title": "At the data source",
        "content": "Securing the Search data sources Search is backend agnostic by design; this means we do not suggest a specific implementation as correct. On this page, we will attempt to bring up some options for you to consider.\nUsing access controls of the data source Whether your data is stored in a database like MySQL and PostgreSQL, or hosted solutions like Google Cloud Storage, the database will likely offer some form of access control. The access control can be broad or fine-grained, extending to table/column/row-level security. Your implementation can leverage the database\u0026rsquo;s access controls to implement GA4GH Passport and Visas to secure your data.\nNot familiar with GA4GH Passports and Visas?\nUsing Presto’s system access control If your implementation uses Presto, you can use Presto\u0026rsquo;s system access control to secure your data source.\nMake a copy of your data If you plan to share a select set of data, you can consider making a copy of all the shared data in a different database/storage instance. Not having sensitive data in your shared data source at all is the most secure solution. If the plan is to share a specific dataset publicly, this is the best option to avoid implementing complicated filters.\n"
    }
    
    , 
    {
        "url": "/docs/security/search-endpoint/",
        "title": "At the search endpoint",
        "content": "Securing the Search endpoint The endpoint should be secured according to the GA4GH Passports and Visas standard as suggested by the GA4GH Data Use and Researcher ID workstream.\n"
    }
    
    , 
    {
        "url": "/docs/getting-started/introduction/",
        "title": "Introduction",
        "content": "{row-divider}\nThe GA4GH Search API The GA4GH Search API specification describes a simple, uniform mechanism to publish, discover, query, and analyze biomedical data. Any “rectangular” data that fits into rows and columns can be represented by GA4GH Search.\nSearch API for data custodians Search API is a perfect solution for data custodians looking to make their biomedical data discoverable and searchable.\n The API is minimalistic by design, which also means minimal resistance to adoption. Search does not prescribe a particular data model. If it fits into rows and columns, you can publish it. Search serves as a general-purpose framework for building federative search-based applications across multiple implementations. Search is backend agnostic. It is possible to implement the API across a large variety of backend datastores.  Search API for data consumers Search API is a perfect solution for data consumers looking to discover and search biomedical data in an interoperable way.\n Search API is RESTful. Read our Open API 3 specification. Search API is discoverable and browsable. See supported table operations Search API is queryable and familiar. Search API\u0026rsquo;s SQL dialect has a familiar interface inspired by current major open source database platforms.  {divider} Quick Links  Full API Specifications\nInstalling Client Libraries\nPublishing Data Examples\nData Consumption Examples\n \n{row-divider}\nInstalling Client Libraries Search has client libraries for R and Python, as well as a command-line interface. We’ll be using these client libraries in the following examples. {divider}  Python R CLI   # Installing the client library form PyPi pip install search-python-client # Installing from Github pip install git+https://github.com/DNAstack/search-python-client --no-cache-dir   # Setup devtools dir.create(path = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), showWarnings = FALSE, recursive = TRUE) install.packages(\u0026#34;devtools\u0026#34;, lib = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), repos = \u0026#34;https://cran.rstudio.com/\u0026#34;) # installing the R client devtools::install_github(\u0026#34;DNAstack/ga4gh-search-client-r\u0026#34;)   Download tables-api-cli-executable.jar. Make it executable (e.g. chmod +x tables-api-cli-executable.jar)\nOptionally create an executable tables script, with contents like this:\n#!/bin/bash /path/to/tables-api-cli-executable.jar $@    \n"
    }
    
    , 
    {
        "url": "/docs/use-exisitng-data/retrofit-a-data-explorer/doc/",
        "title": "Retrofit data explorers",
        "content": "{row-divider}\nMSSNG Clyde focuses on good, readable, responsive documentation. It\u0026rsquo;s side bar indexes in only 2 levels. It\u0026rsquo;s opinionated, because deeply nested manuals are hard to follow and takes much too long to navigate.\n{divider}  Files     ├── content│ ├── category folder│ │ ├── sub-category folder│ │ │ └──_index.md│ │ └── _index.md│ ├── another category |     The code snippet is pulled from this page\n"
    }
    
    , 
    {
        "url": "/docs/use-exisitng-data/tables-in-a-bucket/doc/",
        "title": "Tables-in-a-bucket",
        "content": "{row-divider}\nPhenopackets example Clyde focuses on good, readable, responsive documentation. It\u0026rsquo;s side bar indexes in only 2 levels. It\u0026rsquo;s opinionated, because deeply nested manuals are hard to follow and takes much too long to navigate.\n{divider}  Files     ├── content│ ├── category folder│ │ ├── sub-category folder│ │ │ └──_index.md│ │ └── _index.md│ ├── another category |     The code snippet is pulled from this page\n{row-divider}\nKidsfirst FHIR example Clyde indexes the first level of the sidebar manu by looking for type: product.\nBy default, we use feather icons, and the icon renders as specified by icon: \u0026quot;icon-layers\u0026quot;\nThe example provided is consistent with this example project.\n{divider}  Meta     ---title:\u0026#34;Getting Started\u0026#34;icon:\u0026#34;icon-layers\u0026#34;type :\u0026#34;product\u0026#34;---    The code snippet is pulled from this page\n"
    }
    
    , 
    {
        "url": "/docs/use-exisitng-data/using-preso/doc/",
        "title": "Using Presto",
        "content": "{row-divider}\ndbGaP GECCO Clyde focuses on good, readable, responsive documentation. It\u0026rsquo;s side bar indexes in only 2 levels. It\u0026rsquo;s opinionated, because deeply nested manuals are hard to follow and takes much too long to navigate.\n{divider}  Files     ├── content│ ├── category folder│ │ ├── sub-category folder│ │ │ └──_index.md│ │ └── _index.md│ ├── another category |     The code snippet is pulled from this page\n"
    }
    
    , 
    {
        "url": "/docs/getting-started/provision-data/",
        "title": "Provision Data",
        "content": "{row-divider}\nImplementation The GA4GH API requires the table operations to be implemented to specification for basic discovery and browsing.\nOptional but not required, query operations may be implemented to support querying with SQL.\nThe Search API is backend agnostic, which means any solution that implements the API Specification is valid. You can use your favorite REST application frameworks to implement GA4GH Search or write no code at all with a tables-in-a-bucket implementation.\nThe following examples will get you started experimenting with Search. {divider} Quick Links  Full API Specifications\nPlaceholder for custodian examples\n  {row-divider}\nTables-in-a-bucket example The specification allows for a no-code implementation as a collection of files served statically. This is the easiest way to start experimenting with the GA4GH Search API. As long as your storage bucket conforms to the correct file structure and it has the correct sharing permissions, it is a valid Search implementation.\nA concrete example implementation is available here.\nTest the implementation out:  Python R CLI   Follow along in Colab\n# init search client from search_python_client.search import DrsClient, SearchClient base_url_tiab = \u0026#39;https://storage.googleapis.com/ga4gh-tables-example/\u0026#39; search_client_tiab = SearchClient(base_url=base_url_tiab) # get tables tables_iterator = search_client_tiab.get_table_list() tables = [next(tables_iterator, None) for i in range(10)] tables = list(filter(None, tables)) print(tables) # get table info table_name = tables[0][\u0026#39;name\u0026#39;] table_info = search_client_tiab.get_table_info(table_name) print(table_info) # get table data table_name = tables[0][\u0026#39;name\u0026#39;] table_data_iterator = search_client_tiab.get_table_data(table_name) table_data = [next(table_data_iterator, None) for i in range(10)] table_data = list(filter(None, table_data)) print(table_data)   https://colab.research.google.com/drive/1VOP2IcPjsX4U-DfuiTs7Tr0SVlAD0IMh?usp=sharing \u0026lt;= doesn't work right now.   place holder   \n{divider} Here\u0026rsquo;s how you\u0026rsquo;ll need to organize your folders\n tables: served in response to GET /tables table/{table_name}/info: served in response to GET /table/{table_name}/info. e.g. a table with the name mytable should have a corresponding file table/mytable/info table/{table_name}/data: served in response to GET /table/{table_name}/data. e.g. a table with the name mytable should have a corresponding file table/mytable/data table/{table_name}/data_{pageNumber}, which will be linked in the next_page_url of the first table (e.g. mytable). table/{table_name}/data_models/{schemaFile}: Though not required, data models may be linked via $ref. Data models can also be stored as static JSON documents, and be referred to by relative or absolute URLs.   \n{row-divider}\nTry out a reference implementation This example was shown as a demo during the 2020 GA4GH Plenary. This app will run a reference Search implementation on docker and use a Presto instance hosted by DNAstack as the data source.\nYou’ll need docker set up on your system to run the Spring app, and you’ll need to have one of the client libraries installed from the Introduction Section.\nhe Docker commands will download and start a PostgreSQL container and the reference Search implementation. If you would like to experiment with the application further, you can check out the source code and configuration options here. {divider}  30 second quick start   docker pull postgres:latest docker run -d --rm --network=\u0026#34;host\u0026#34; --name dnastack-ga4gh-search-db -e POSTGRES_USER=ga4ghsearchadapterpresto -e POSTGRES_PASSWORD=ga4ghsearchadapterpresto postgres docker pull dnastack/ga4gh-search-adapter-presto:latest docker run --rm --name dnastack-ga4gh-search -p 8089:8089 -e PRESTO_DATASOURCE_URL=https://presto-public.prod.dnastack.com -e SPRING_PROFILES_ACTIVE=no-auth dnastack/ga4gh-search-adapter-presto:latest      Python R CLI   # init search client from search_python_client.search import DrsClient, SearchClient base_url_tiab = 'http://localhost:8089/' search_client_tiab = SearchClient(base_url=base_url_tiab) # get tables tables_iterator = search_client_tiab.get_table_list() tables = [next(tables_iterator, None) for i in range(10)] tables = list(filter(None, tables)) print(tables) # get table info table_name = tables[0]['name'] table_info = search_client_tiab.get_table_info(table_name) print(table_info) # get table data table_name = tables[0]['name'] table_data_iterator = search_client_tiab.get_table_data(table_name) table_data = [next(table_data_iterator, None) for i in range(10)] table_data = list(filter(None, table_data)) print(table_data)   devtools::install_github(\u0026quot;DNAstack/ga4gh-search-client-r\u0026quot;) library(httr) tables \u0026lt;- ga4gh.search::ga4gh_list_tables(\u0026quot;http://localhost:8089\u0026quot;) print(tables) search_result \u0026lt;- ga4gh.search::ga4gh_search(\u0026quot;http://localhost:8089\u0026quot;, \u0026quot;SELECT sample_phenopackets.ga4gh_tables.gecco_phenopackets\u0026quot;) print(tables)   place holder    \n"
    }
    
    , 
    {
        "url": "/docs/getting-started/consume-data/",
        "title": "Consume Data",
        "content": "{row-divider}\nQueries The Search API supports query operation through SQL statements.\nThe GA4GH Search API\u0026rsquo;s SQL dialect has a familiar interface inspired by current major open source database platforms, including Presto SQL, PostgreSQL, MySQL, and BigQuery. If you have prior experience with these database platforms, you\u0026rsquo;ll feel right at home with only minor adjustments.\nSupported SQL functions\nSupported SQL grammar\n{divider}  Example #1 Example #2   This query returns all female patients from the patient table.\n/* you can scroll on this tab */ SELECT * FROM kidsfirst.ga4gh_tables.patient WHERE Json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;) = \u0026#39;female\u0026#39; LIMIT 5;   This query returns all conditions observed in female patients from the patient table.\n/* you can scroll on this tab */ SELECT Json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) AS disease, Json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) AS identifier FROM kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id = REPLACE(Json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE Json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;) = \u0026#39;female\u0026#39; LIMIT 5;    \n{row-divider}\nIssuing queries using the Search API Search is a standard REST API. This means Search can be accessed through standard HTTP calls.\nWhile Search API can be navigated using programs like cURL or Postman, it is best accessed programmatically. The results could return multiple pages, which is easier to navigate with programmatic access.\nOnce you\u0026rsquo;ve visited a page and consumed data from it, you can\u0026rsquo;t go back to it or refresh.\nOn the right, we provide examples to consume data from the Search API using the GA4GH Commandline Interface, the R client, Python, and cURL.\n Need help installing client libraries?\n {divider}  Python R CLI cURL   Follow Along in Google Colab\n# Installing the client library form PyPi pip install search-python-client # Installing from Github pip install git+https://github.com/DNAstack/search-python-client --no-cache-dir # Building the query from search_python_client.search import DrsClient, SearchClient base_url = \u0026#39;https://search-presto-public.staging.dnastack.com\u0026#39; search_client = SearchClient(base_url=base_url) query = \u0026#34;\u0026#34;\u0026#34; SELECT Json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) AS disease, Json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) AS identifier FROM kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id = REPLACE(Json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE Json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;) = \u0026#39;female\u0026#39; LIMIT 5 \u0026#34;\u0026#34;\u0026#34; # Executing the query table_data_iterator = search_client.search_table(query) for item in table_data_iterator: print(item) # Results {\u0026#39;disease\u0026#39;: \u0026#39;Aortic atresia\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Aortic atresia|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Mitral atresia\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Mitral atresia|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Hypoplasia ascending aorta\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Hypoplasia ascending aorta|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Hypoplastic left heart syndrome\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Hypoplastic left heart syndrome|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Hypoplastic left ventricle (subnormal cavity volume)\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Hypoplastic left ventricle (subnormal cavity volume)|None\u0026#39;}   Follow Along in Google Colab\n# installing devtools dir.create(path = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), showWarnings = FALSE, recursive = TRUE) install.packages(\u0026#34;devtools\u0026#34;, lib = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), repos = \u0026#34;https://cran.rstudio.com/\u0026#34;) # installing the R client devtools::install_github(\u0026#34;DNAstack/ga4gh-search-client-r\u0026#34;) # Making the request library(httr) conditionsInFemalePatients \u0026lt;- ga4gh.search::ga4gh_search(\u0026#34;https://search-presto-public.staging.dnastack.com\u0026#34;, \u0026#34;select json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) as disease, json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) as identifier from kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id=replace(json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;)=\u0026#39;female\u0026#39; limit 5\u0026#34;) # View the results print(conditionsInFemalePatients) Output:\ndisease 1 Aortic atresia 2 Mitral atresia 3 Hypoplasia ascending aorta 4 Hypoplastic left heart syndrome 5 Hypoplastic left ventricle (subnormal cavity volume) identifier 1 Condition|SD_PREASA7S|272|Aortic atresia|None 2 Condition|SD_PREASA7S|272|Mitral atresia|None 3 Condition|SD_PREASA7S|272|Hypoplasia ascending aorta|None 4 Condition|SD_PREASA7S|272|Hypoplastic left heart syndrome|None 5 Condition|SD_PREASA7S|272|Hypoplastic left ventricle (subnormal cavity volume)|None   ./dnastack-search query -q \u0026#34;select json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) as disease, json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) as identifier from kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id=replace(json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;)=\u0026#39;female\u0026#39; limit 5\u0026#34;   These requests This query returns all female patients from the patient table.\ncurl --request POST \\  --url https://search-presto-public.staging.dnastack.com/search \\  --header \u0026#39;content-type: application/json\u0026#39; \\  --data \u0026#39;{ \u0026#34;query\u0026#34;: \u0026#34;select * from kidsfirst.ga4gh_tables.patient WHERE json_extract_scalar(patient, \u0026#39;\\\u0026#39;\u0026#39;$.gender\u0026#39;\\\u0026#39;\u0026#39;)=\u0026#39;\\\u0026#39;\u0026#39;female\u0026#39;\\\u0026#39;\u0026#39; limit 5\u0026#34;}\u0026#39; This query returns all conditions observed in female patients from the patient table.\ncurl --request POST \\  --url https://search-presto-public.staging.dnastack.com/search \\  --header \u0026#39;content-type: application/json\u0026#39; \\  --data \u0026#39;{ \u0026#34;query\u0026#34;: \u0026#34;select json_extract_scalar(ncpi_disease, \u0026#39;\\\u0026#39;\u0026#39;$.code.text\u0026#39;\\\u0026#39;\u0026#39;) as disease, json_extract_scalar(ncpi_disease, \u0026#39;\\\u0026#39;\u0026#39;$.identifier[0].value\u0026#39;\\\u0026#39;\u0026#39;) as identifier from kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id=replace(json_extract_scalar(ncpi_disease, \u0026#39;\\\u0026#39;\u0026#39;$.subject.reference\u0026#39;\\\u0026#39;\u0026#39;), \u0026#39;\\\u0026#39;\u0026#39;Patient/\u0026#39;\\\u0026#39;\u0026#39;) WHERE json_extract_scalar(patient, \u0026#39;\\\u0026#39;\u0026#39;$.gender\u0026#39;\\\u0026#39;\u0026#39;)=\u0026#39;\\\u0026#39;\u0026#39;female\u0026#39;\\\u0026#39;\u0026#39; limit 5\u0026#34;}\u0026#39;    \n"
    }
    
    , 
    {
        "url": "/docs/getting-started/upload-result/",
        "title": "Upload results",
        "content": "{row-divider}\nWe\u0026rsquo;re working on it!\n"
    }
    
    , 
    {
        "url": "/docs/index.json",
        "title": "Docs",
        "content": ""
    }
    
]