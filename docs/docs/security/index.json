[{"url":"/docs/security/data-source/","title":"At the data source","content":"Securing the Search data sources Search is backend agnostic by design; this means we do not suggest a specific implementation as correct. On this page, we will attempt to bring up some options for you to consider.\nUsing access controls of the data source Whether your data is stored in a database like MySQL and PostgreSQL, or hosted solutions like Google Cloud Storage, the database will likely offer some form of access control. The access control can be broad or fine-grained, extending to table/column/row-level security. Your implementation can leverage the database\u0026rsquo;s access controls to implement GA4GH Passport and Visas to secure your data.\nNot familiar with GA4GH Passports and Visas?\nUsing Presto’s system access control If your implementation uses Presto, you can use Presto\u0026rsquo;s system access control to secure your data source.\nMake a copy of your data If you plan to share a select set of data, you can consider making a copy of all the shared data in a different database/storage instance. Not having sensitive data in your shared data source at all is the most secure solution. If the plan is to share a specific dataset publicly, this is the best option to avoid implementing complicated filters.\n"},{"url":"/docs/security/search-endpoint/","title":"At the search endpoint","content":"Securing the Search endpoint The endpoint should be secured according to the GA4GH Passports and Visas standard as suggested by the GA4GH Data Use and Researcher ID workstream.\n"},{"url":"/docs/getting-started/introduction/","title":"Introduction","content":"{row-divider}\nThe GA4GH Search API The GA4GH Search API specification describes a simple, uniform mechanism to publish, discover, query, and analyze biomedical data. Any “rectangular” data that fits into rows and columns can be represented by GA4GH Search.\nSearch API for data custodians Search API is a perfect solution for data custodians looking to make their biomedical data discoverable and searchable.\n The API is minimalistic by design, which also means minimal resistance to adoption. Search does not prescribe a particular data model. If it fits into rows and columns, you can publish it. Search serves as a general-purpose framework for building federative search-based applications across multiple implementations. Search is backend agnostic. It is possible to implement the API across a large variety of backend datastores.  Search API for data consumers Search API is a perfect solution for data consumers looking to discover and search biomedical data in an interoperable way.\n Search API is RESTful. Read our Open API 3 specification. Search API is discoverable and browsable. See supported table operations Search API is queryable and familiar. Search API\u0026rsquo;s SQL dialect has a familiar interface inspired by current major open source database platforms.  {divider} Quick Links  Full API Specifications\nInstalling Client Libraries\nPublishing Data Examples\nData Consumption Examples\n \n{row-divider}\nInstalling Client Libraries Search has client libraries for R and Python, as well as a command-line interface. We’ll be using these client libraries in the following examples. {divider}  Python R CLI   # Installing the client library form PyPi pip install search-python-client # Installing from Github pip install git+https://github.com/DNAstack/search-python-client --no-cache-dir   # Setup devtools dir.create(path = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), showWarnings = FALSE, recursive = TRUE) install.packages(\u0026#34;devtools\u0026#34;, lib = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), repos = \u0026#34;https://cran.rstudio.com/\u0026#34;) # installing the R client devtools::install_github(\u0026#34;DNAstack/ga4gh-search-client-r\u0026#34;)   This CLI requires Java 11+ on your system\ncurl https://storage.googleapis.com/ga4gh-search-cli/tables-cli-2.1-55-gc484f8b-executable.jar \u0026gt; search-cli chmod +x search-cli mv search-cli /usr/local/bin # (somewhere on your search path) search-cli --version You should see:\ntables-api-cli Version : 1.0-0.2.1-55-gc484f8b    \n"},{"url":"/docs/use-exisitng-data/retrofit-a-data-explorer/doc/","title":"Retrofit data explorers","content":"{row-divider}\nMSSNG We\u0026rsquo;re working on it!\n{divider}  Files     ├── content│ ├── category folder│ │ ├── sub-category folder│ │ │ └──_index.md│ │ └── _index.md│ ├── another category |    The code snippet is pulled from this page\n"},{"url":"/docs/use-exisitng-data/tables-in-a-bucket/doc/","title":"Tables-in-a-bucket","content":"What is a phenopacket? Phenopacket is a GA4GH approved standard file format for sharing phenotypic information.\nFind documentation for phenopackets-schema here.\nWhat does it contain?  A set of mandatory and optional fields to share information about a patient or participant’s phenotype Optional fields may include clinical diagnosis, age of onset, results from lab tests, and disease severity.  An example of the JSON structure can be found here.\nPreparing the data into a GA4GH Search application If you need some phenopackets data to follow this example, consider the following:\n Human Phenotype Ontology phenopackets downloaded from a publicly available metadata source: https://zenodo.org/record/3905420#.X3Sd2pNKj6h. Gecco Biosample phenopackets.   Clone this repository: https://github.com/DNAstack/tables-loader All phenopacket JSON files should be added under \u0026lt;repo_root\u0026gt;/resources/phenopackets Create a Google storage bucket with public access. Creating Storage Buckets Create a service account and grant \u0026ldquo;Storage Admin\u0026rdquo; access to your storage bucket. You should automatically begin downloading the access key. *Store this access key somewhere safe, you\u0026rsquo;ll need it later  Running the Spring application  Export this environment variable: GOOGLE_APPLICATION_CREDENTIALS=\u0026lt;service_account_json_file_path\u0026gt; Start the Spring application. (With your Java IDE or mvn clean spring-boot:run in bash) You should see the following at http://localhost:8080/: Welcome to Phenopackets tables loader application!  Available API endpoints /create-tables-files/{tableStructure}: Creates tables, info and data files for all phenopackets JSON present in \u0026lt;repo_root\u0026gt;/resources/phenopackets directory\n/upload-files/{tableStructure} Uploads all files under \u0026lt;repo_root\u0026gt;/resources/ga4gh-phenopackets-example/\u0026lt;by_subject|flat\u0026gt; to Google cloud storage bucket ga4gh-phenopackets-example\nphenopacket/{tableStructure}/tables Gets \u0026lt;repo_root\u0026gt;/resources/ga4gh-phenopackets-example/\u0026lt;by_subject|flat\u0026gt;/tables json file\nphenopacket/{tableStructure}/table/{tableName}/info Gets \u0026lt;repo_root\u0026gt;/resources/ga4gh-phenopackets-example/\u0026lt;by_subject|flat\u0026gt;/table/info file\nphenopacket/{tableStructure}/table/{tableName}/data Gets \u0026lt;repo_root\u0026gt;/resources/ga4gh-phenopackets-example/\u0026lt;by_subject|flat\u0026gt;/table/data file\n"},{"url":"/docs/use-exisitng-data/using-preso/doc/","title":"Using Presto","content":"The dbGaP GECCO example In the provision data section, we\u0026rsquo;ve shown a quick start recipe with the ga4gh-search-adapter-presto docker container connected to a Presto instance hosted at https://presto-public.prod.dnastack.com. This section provides more information on how this was accomplished.\nQuick Links  ga4gh-search-adapter-presto\nOpen API 3 Reference\nFull GA4GH Search Specification\nTable Object Specification\nSearch API’s SQL dialect\n  Prerequisites The following is required before we start.\n Java 11+ A Presto server you can access anonymously over HTTP(S). Git   If you don\u0026rsquo;t have a Presto server to work against and you wish to try the app, try using https://presto-public.prod.dnastack.com as the data source.\n 1. Building the Presto Adapter App\nClone the repository\ngit clone https://github.com/DNAstack/ga4gh-search-adapter-presto.git Build the app\nmvn clean package 2. Configuration\nFor a minimal configuration, we need to provide two parameters, PRESTO_DATASOURCE_URL and SPRING_PROFILES_ACTIVE.\nPRESTO_DATASOURCE_URL points to the Presto server you wish to expose with a Search API.\nClone the repository:\nexport PRESTO_DATASOURCE_URL=https://\u0026lt;your-presto-server\u0026gt; export SPRING_PROFILES_ACTIVE=no-auth The adapter app requires a local PostgreSQL database connection. To start the app locally with the default settings, you can spin up the database with this docker command:\ndocker run -d -p 5432:5432 --name ga4ghsearchadapterpresto -e POSTGRES_USER=ga4ghsearchadapterpresto -e POSTGRES_PASSWORD=ga4ghsearchadapterpresto postgres 3. Run the adapter app\nmvn clean spring-boot:run Your application should now be accessible at http://localhost:8089/tables\nTo test the app out, follow the consuming data section.\nFurther Configuration Further configuration can be found at: https://github.com/DNAstack/ga4gh-search-adapter-presto\n"},{"url":"/docs/getting-started/provision-data/","title":"Provision Data","content":"{row-divider}\nImplementation The GA4GH API requires table operations to be implemented to specification for basic discovery and browsing.\nOptional but not required, query operations may be implemented to support querying with SQL.\nThe Search API is backend agnostic, which means any solution that implements the API specification is valid. You can use your favorite REST application frameworks to implement GA4GH Search Endpoints or a hosted blob store for a tables-in-a-bucket implementation requiring no code.\nCheckout the following examples for some inspiration. {divider} Quick Links  Full API Specifications\nPlaceholder for custodian examples\n  {row-divider}\nTables-in-a-bucket example The specification allows for a no-code implementation as a collection of files served statically. This is the easiest way to start experimenting with the GA4GH Search API. As long as your storage bucket conforms to the correct file structure and it has the correct sharing permissions, it is a valid Search implementation.\nA concrete example implementation is available here and try browsing this implementation with these commands.\n{divider} Here\u0026rsquo;s how you\u0026rsquo;ll need to organize your folders\n tables: served in response to GET /tables table/{table_name}/info: served in response to GET /table/{table_name}/info. e.g. a table with the name mytable should have a corresponding file table/mytable/info table/{table_name}/data: served in response to GET /table/{table_name}/data. e.g. a table with the name mytable should have a corresponding file table/mytable/data table/{table_name}/data_{pageNumber}, which will be linked in the next_page_url of the first table (e.g. mytable). table/{table_name}/data_models/{schemaFile}: Though not required, data models may be linked via $ref. Data models can also be stored as static JSON documents, and be referred to by relative or absolute URLs.   \n{row-divider}\nTry out a reference implementation This example was shown as a demo during the 2020 GA4GH Plenary. This app will run a reference Search implementation on docker and use a Presto instance hosted by DNAstack as the data source.\nYou’ll need docker set up on your system to run the Spring app, and you’ll need to have one of the client libraries installed from the Introduction Section.\nFurther information about this example can be found here. {divider}  30 second quick start   docker pull postgres:latest docker run -d --rm --network=\u0026#34;host\u0026#34; --name dnastack-ga4gh-search-db -e POSTGRES_USER=ga4ghsearchadapterpresto -e POSTGRES_PASSWORD=ga4ghsearchadapterpresto postgres docker pull dnastack/ga4gh-search-adapter-presto:latest docker run --rm --name dnastack-ga4gh-search -p 8089:8089 -e PRESTO_DATASOURCE_URL=https://presto-public.prod.dnastack.com -e SPRING_PROFILES_ACTIVE=no-auth dnastack/ga4gh-search-adapter-presto:latest    \n Python R CLI   # init search client from search_python_client.search import DrsClient, SearchClient base_url = \u0026#39;http://localhost:8089/\u0026#39; search_client = SearchClient(base_url=base_url) # get tables tables_iterator = search_client.get_table_list() tables = [next(tables_iterator, None) for i in range(10)] tables = list(filter(None, tables)) print(tables) # get table info table_name = \u0026#34;sample_phenopackets.ga4gh_tables.gecco_phenopackets\u0026#34; table_info = search_client.get_table_info(table_name) print(table_info) # get table data table_name = \u0026#34;sample_phenopackets.ga4gh_tables.gecco_phenopackets\u0026#34; table_data_iterator = search_client.get_table_data(table_name) table_data = [next(table_data_iterator, None) for i in range(10)] table_data = list(filter(None, table_data)) print(table_data)   # Fetch table list library(httr) tables \u0026lt;- ga4gh.search::ga4gh_list_tables(\u0026#34;http://localhost:8089\u0026#34;) print(tables) # Try a query search_result \u0026lt;- ga4gh.search::ga4gh_search(\u0026#34;http://localhost:8089\u0026#34;, \u0026#34;SELECT sample_phenopackets.ga4gh_tables.gecco_phenopackets\u0026#34;) print(tables)   List tables\nsearch-cli list --api-url http://localhost:8089 Get table info\nsearch-cli info dbgap_demo.scr_gecco_susceptibility.sample_multi --api-url http://localhost:8089 Get table data\nsearch-cli data dbgap_demo.scr_gecco_susceptibility.sample_multi --api-url http://localhost:8089     "},{"url":"/docs/getting-started/consume-data/","title":"Consume Data","content":"{row-divider}\nBrowsing The minimum Search API implementations will support browsing by table. This means these operations from the API specs are supported for table by table browsing.\nOn the right is example code to browse the tables-in-a-bucket implementation of Search. {divider}  Python R CLI   Follow along in Colab\n# init search client from search_python_client.search import DrsClient, SearchClient base_url_tiab = \u0026#39;https://storage.googleapis.com/ga4gh-tables-example/\u0026#39; search_client_tiab = SearchClient(base_url=base_url_tiab) # get tables tables_iterator = search_client_tiab.get_table_list() tables = [next(tables_iterator, None) for i in range(10)] tables = list(filter(None, tables)) print(tables) # get table info table_name = tables[0][\u0026#39;name\u0026#39;] table_info = search_client_tiab.get_table_info(table_name) print(table_info) # get table data table_name = tables[0][\u0026#39;name\u0026#39;] table_data_iterator = search_client_tiab.get_table_data(table_name) table_data = [next(table_data_iterator, None) for i in range(10)] table_data = list(filter(None, table_data)) print(table_data)   Under construction https://colab.research.google.com/drive/1VOP2IcPjsX4U-DfuiTs7Tr0SVlAD0IMh?usp=sharing \u0026lt;= doesn't work right now.   Get list of tables\nsearch-cli list --api-url https://storage.googleapis.com/ga4gh-tables-example search-cli info subjects --api-url https://storage.googleapis.com/ga4gh-tables-example search-cli data subjects --api-url https://storage.googleapis.com/ga4gh-tables-example   \n{row-divider}\nQueries The Search API supports query operation through SQL statements.\nThe GA4GH Search API\u0026rsquo;s SQL dialect has a familiar interface inspired by current major open source database platforms, including Presto SQL, PostgreSQL, MySQL, and BigQuery. If you have prior experience with these database platforms, you\u0026rsquo;ll feel right at home with only minor adjustments.\nSupported SQL functions\nSupported SQL grammar\n{divider}  Example #1 Example #2   This query returns all female patients from the patient table.\n/* you can scroll on this tab */ SELECT * FROM kidsfirst.ga4gh_tables.patient WHERE Json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;) = \u0026#39;female\u0026#39; LIMIT 5;   This query returns all conditions observed in female patients from the patient table.\n/* you can scroll on this tab */ SELECT Json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) AS disease, Json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) AS identifier FROM kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id = REPLACE(Json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE Json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;) = \u0026#39;female\u0026#39; LIMIT 5;    \n{row-divider}\nIssuing queries using the Search API Search is a standard REST API. This means Search can be accessed through standard HTTP calls.\nWhile Search API can be navigated using programs like cURL or Postman, it is best accessed programmatically. The results could return multiple pages, which is easier to navigate with programmatic access.\nOnce you\u0026rsquo;ve visited a page and consumed data from it, you can\u0026rsquo;t go back to it or refresh.\nOn the right, we provide examples to consume data from the Search API using the GA4GH Commandline Interface, the R client, Python, and cURL.\n Need help installing client libraries?\n {divider}  Python R CLI cURL   Follow Along in Google Colab\n# Installing the client library form PyPi pip install search-python-client # Installing from Github pip install git+https://github.com/DNAstack/search-python-client --no-cache-dir # Building the query from search_python_client.search import DrsClient, SearchClient base_url = \u0026#39;https://search-presto-public.staging.dnastack.com\u0026#39; search_client = SearchClient(base_url=base_url) query = \u0026#34;\u0026#34;\u0026#34; SELECT Json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) AS disease, Json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) AS identifier FROM kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id = REPLACE(Json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE Json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;) = \u0026#39;female\u0026#39; LIMIT 5 \u0026#34;\u0026#34;\u0026#34; # Executing the query table_data_iterator = search_client.search_table(query) for item in table_data_iterator: print(item) # Results {\u0026#39;disease\u0026#39;: \u0026#39;Aortic atresia\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Aortic atresia|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Mitral atresia\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Mitral atresia|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Hypoplasia ascending aorta\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Hypoplasia ascending aorta|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Hypoplastic left heart syndrome\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Hypoplastic left heart syndrome|None\u0026#39;} {\u0026#39;disease\u0026#39;: \u0026#39;Hypoplastic left ventricle (subnormal cavity volume)\u0026#39;, \u0026#39;identifier\u0026#39;: \u0026#39;Condition|SD_PREASA7S|272|Hypoplastic left ventricle (subnormal cavity volume)|None\u0026#39;}   Follow Along in Google Colab\n# installing devtools dir.create(path = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), showWarnings = FALSE, recursive = TRUE) install.packages(\u0026#34;devtools\u0026#34;, lib = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), repos = \u0026#34;https://cran.rstudio.com/\u0026#34;) # installing the R client devtools::install_github(\u0026#34;DNAstack/ga4gh-search-client-r\u0026#34;) # Making the request library(httr) conditionsInFemalePatients \u0026lt;- ga4gh.search::ga4gh_search(\u0026#34;https://search-presto-public.staging.dnastack.com\u0026#34;, \u0026#34;select json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) as disease, json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) as identifier from kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id=replace(json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;)=\u0026#39;female\u0026#39; limit 5\u0026#34;) # View the results print(conditionsInFemalePatients) Output:\ndisease 1 Aortic atresia 2 Mitral atresia 3 Hypoplasia ascending aorta 4 Hypoplastic left heart syndrome 5 Hypoplastic left ventricle (subnormal cavity volume) identifier 1 Condition|SD_PREASA7S|272|Aortic atresia|None 2 Condition|SD_PREASA7S|272|Mitral atresia|None 3 Condition|SD_PREASA7S|272|Hypoplasia ascending aorta|None 4 Condition|SD_PREASA7S|272|Hypoplastic left heart syndrome|None 5 Condition|SD_PREASA7S|272|Hypoplastic left ventricle (subnormal cavity volume)|None   search-cli query -q \u0026#34;select json_extract_scalar(ncpi_disease, \u0026#39;$.code.text\u0026#39;) as disease, json_extract_scalar(ncpi_disease, \u0026#39;$.identifier[0].value\u0026#39;) as identifier from kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id=replace(json_extract_scalar(ncpi_disease, \u0026#39;$.subject.reference\u0026#39;), \u0026#39;Patient/\u0026#39;) WHERE json_extract_scalar(patient, \u0026#39;$.gender\u0026#39;)=\u0026#39;female\u0026#39; limit 5\u0026#34; --api-url https://search-presto-public.staging.dnastack.com   These requests This query returns all female patients from the patient table.\ncurl --request POST \\  --url https://search-presto-public.staging.dnastack.com/search \\  --header \u0026#39;content-type: application/json\u0026#39; \\  --data \u0026#39;{ \u0026#34;query\u0026#34;: \u0026#34;select * from kidsfirst.ga4gh_tables.patient WHERE json_extract_scalar(patient, \u0026#39;\\\u0026#39;\u0026#39;$.gender\u0026#39;\\\u0026#39;\u0026#39;)=\u0026#39;\\\u0026#39;\u0026#39;female\u0026#39;\\\u0026#39;\u0026#39; limit 5\u0026#34;}\u0026#39; This query returns all conditions observed in female patients from the patient table.\ncurl --request POST \\  --url https://search-presto-public.staging.dnastack.com/search \\  --header \u0026#39;content-type: application/json\u0026#39; \\  --data \u0026#39;{ \u0026#34;query\u0026#34;: \u0026#34;select json_extract_scalar(ncpi_disease, \u0026#39;\\\u0026#39;\u0026#39;$.code.text\u0026#39;\\\u0026#39;\u0026#39;) as disease, json_extract_scalar(ncpi_disease, \u0026#39;\\\u0026#39;\u0026#39;$.identifier[0].value\u0026#39;\\\u0026#39;\u0026#39;) as identifier from kidsfirst.ga4gh_tables.ncpi_disease disease INNER JOIN kidsfirst.ga4gh_tables.patient patient ON patient.id=replace(json_extract_scalar(ncpi_disease, \u0026#39;\\\u0026#39;\u0026#39;$.subject.reference\u0026#39;\\\u0026#39;\u0026#39;), \u0026#39;\\\u0026#39;\u0026#39;Patient/\u0026#39;\\\u0026#39;\u0026#39;) WHERE json_extract_scalar(patient, \u0026#39;\\\u0026#39;\u0026#39;$.gender\u0026#39;\\\u0026#39;\u0026#39;)=\u0026#39;\\\u0026#39;\u0026#39;female\u0026#39;\\\u0026#39;\u0026#39; limit 5\u0026#34;}\u0026#39;    \n{row-divider}\nMore Examples dbGaP GECCO Example This is a public implementation of Search. Feel free to follow along with the examples and explore this endpoint with your own script.  Python R CLI   Follow along in Colab\n# init search client from search_python_client.search import DrsClient, SearchClient base_url = \u0026#39;https://search-presto-public.prod.dnastack.com/\u0026#39; search_client = SearchClient(base_url=base_url) # Find available tables tables_iterator = search_client.get_table_list() tables = list(tables_iterator) import pprint pprint.pprint(tables) #Get more information about a table returned table_info = search_client.get_table_info(\u0026#34;dbgap_demo.scr_gecco_susceptibility.subject_phenotypes_multi\u0026#34;) pprint.pprint(table_info) # Dig into the table a little further table_data_iterator = search_client.get_table_data(\u0026#34;dbgap_demo.scr_gecco_susceptibility.subject_phenotypes_multi\u0026#34;) # Limit to first 10 items tables = [next(table_data_iterator, None) for i in range(10)] tables = list(filter(None, tables)) pprint.pprint(tables) # Select all items from the CPS-II study  query = \u0026#34;\u0026#34;\u0026#34; SELECT * FROM dbgap_demo.scr_gecco_susceptibility.subject_phenotypes_multi WHERE study = \u0026#39;CPS-II\u0026#39; LIMIT 5 \u0026#34;\u0026#34;\u0026#34; # Executing the query table_data_iterator = search_client.search_table(query) for item in table_data_iterator: print(item)   Follow along in Colab\n# installing devtools dir.create(path = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), showWarnings = FALSE, recursive = TRUE) install.packages(\u0026#34;devtools\u0026#34;, lib = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), repos = \u0026#34;https://cran.rstudio.com/\u0026#34;) # installing the R client devtools::install_github(\u0026#34;DNAstack/ga4gh-search-client-r\u0026#34;) # Making the request library(httr) ga4gh.search::ga4gh_list_tables(\u0026#34;https://search-presto-public.prod.dnastack.com\u0026#34;) # Select all items from the CPS-II study  query \u0026lt;- \u0026#34;SELECT * FROM dbgap_demo.scr_gecco_susceptibility.subject_phenotypes_multi WHERE study = \u0026#39;CPS-II\u0026#39; LIMIT 5\u0026#34; # Executing the query ga4gh.search::ga4gh_search(\u0026#34;https://search-presto-public.prod.dnastack.com\u0026#34;, query)   List tables\nsearch-cli list --api-url \u0026#34;https://search-presto-public.prod.dnastack.com\u0026#34; Get table info\nsearch-cli info dbgap_demo.scr_gecco_susceptibility.subject_phenotypes_multi --api-url \u0026#34;https://search-presto-public.prod.dnastack.com\u0026#34; Now run a query and pipe the results to a file called results.txt\nsearch-cli query -q \u0026#34;SELECT * FROM dbgap_demo.scr_gecco_susceptibility.subject_phenotypes_multi WHERE study = \u0026#39;CPS-II\u0026#39; LIMIT 5\u0026#34; \\  --api-url \u0026#34;https://search-presto-public.prod.dnastack.com\u0026#34; \u0026gt; results.txt   \n{divider}\n COVID Cloud Example This is a public implementation of Search. It is connected to multiple sources of data related to COVID19, such as data from USA Facts used in this example.  Python R CLI   Follow along in Colab\nfrom search_python_client.search import DrsClient, SearchClient base_url = \u0026#39;https://search-presto-public-covid19.prod.dnastack.com/\u0026#39; search_client = SearchClient(base_url=base_url) # Find available tables tables_iterator = search_client.get_table_list() tables = list(tables_iterator) import pprint pprint.pprint(tables) #Get more information about a table returned table_info = search_client.get_table_info(\u0026#34;coronavirus_public.covid19_usafacts.deaths\u0026#34;) pprint.pprint(table_info) # Dig into the table a little further table_data_iterator = search_client.get_table_data(\u0026#34;coronavirus_public.covid19_usafacts.deaths\u0026#34;) # Limit to first 10 items tables = [next(table_data_iterator, None) for i in range(10)] tables = list(filter(None, tables)) pprint.pprint(tables) # Select all corona death cases from the state of LA, limited to 25 results and sorted by county name. query = \u0026#34;\u0026#34;\u0026#34; SELECT * FROM coronavirus_public.covid19_usafacts.deaths WHERE state = \u0026#39;LA\u0026#39; ORDER BY county_name LIMIT 25 \u0026#34;\u0026#34;\u0026#34; # Executing the query table_data_iterator = search_client.search_table(query) for item in table_data_iterator: print(item)   Follow along in Colab\n# installing devtools dir.create(path = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), showWarnings = FALSE, recursive = TRUE) install.packages(\u0026#34;devtools\u0026#34;, lib = Sys.getenv(\u0026#34;R_LIBS_USER\u0026#34;), repos = \u0026#34;https://cran.rstudio.com/\u0026#34;) # installing the R client devtools::install_github(\u0026#34;DNAstack/ga4gh-search-client-r\u0026#34;) # Making the request library(httr) ga4gh.search::ga4gh_list_tables(\u0026#34;https://search-presto-public-covid19.prod.dnastack.com\u0026#34;) # Select all COVID death cases from the state of LA, limited to 25 results and sorted by county name. query \u0026lt;- \u0026#34;SELECT * FROM coronavirus_public.covid19_usafacts.deaths WHERE state = \u0026#39;LA\u0026#39; ORDER BY county_name LIMIT 25\u0026#34; # Executing the query ga4gh.search::ga4gh_search(\u0026#34;https://search-presto-public-covid19.prod.dnastack.com\u0026#34;, query)   List tables\nsearch-cli list --api-url \u0026#34;https://search-presto-public-covid19.prod.dnastack.com\u0026#34; Get table info\nsearch-cli info coronavirus_public.covid19_usafacts.deaths --api-url \u0026#34;https://search-presto-public-covid19.prod.dnastack.com\u0026#34; Now run a query and pipe the results to a file called results.txt\nsearch-cli query -q \u0026#34;SELECT * FROM coronavirus_public.covid19_usafacts.deaths WHERE state = \u0026#39;LA\u0026#39; ORDER BY county_name LIMIT 25\u0026#34; \\  --api-url \u0026#34;https://search-presto-public-covid19.prod.dnastack.com\u0026#34; \u0026gt; results.txt   \n"},{"url":"/docs/getting-started/upload-result/","title":"Upload results","content":"{row-divider}\nWe\u0026rsquo;re working on it!\n"},{"url":"/docs/index.json","title":"Docs","content":""}]